{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5cedd47",
   "metadata": {},
   "source": [
    "# Local Manga AI\n",
    "\n",
    "This notebook launches a fully-local pipeline: **Qwen2.5 → SDXL → Page Composer** and can optionally expose a public HTTPS URL via **Cloudflare Tunnel**.\n",
    "\n",
    "Model folders:\n",
    "- `models/qwen2.5/`\n",
    "- `models/sdxl/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cafbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress Hugging Face Hub deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*resume_download.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*local_dir_use_symlinks.*\")\n",
    "\n",
    "# Runtime settings (run this BEFORE loading any torch/diffusers models)\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
    "\n",
    "# Hugging Face token for gated models\n",
    "os.environ[\"MANGA_AI_HF_TOKEN\"] = \"www\"\n",
    "\n",
    "print(\"PYTORCH_CUDA_ALLOC_CONF=\", os.environ.get(\"PYTORCH_CUDA_ALLOC_CONF\"))\n",
    "print(\"Hugging Face token set for gated models\")\n",
    "print(\"HF deprecation warnings suppressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f525514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect project root (folder that contains both ./scripts and ./models)\n",
    "CWD = Path.cwd().resolve()\n",
    "ROOT = CWD\n",
    "\n",
    "if not ((ROOT / \"scripts\").exists() and (ROOT / \"models\").exists()):\n",
    "    if (ROOT.parent / \"scripts\").exists() and (ROOT.parent / \"models\").exists():\n",
    "        ROOT = ROOT.parent.resolve()\n",
    "\n",
    "if not ((ROOT / \"scripts\").exists() and (ROOT / \"models\").exists()):\n",
    "    raise RuntimeError(\n",
    "        \"Could not locate project ROOT. Expected folders 'scripts' and 'models' in the working directory (or its parent). \"\n",
    "        f\"CWD={CWD}\"\n",
    "    )\n",
    "\n",
    "# Make sure imports like `from scripts...` work\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "print(\"CWD:\", CWD)\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"Python:\", sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca83190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from scripts.model_downloader import ensure_models_downloaded\n",
    "\n",
    "QWEN_DIR = Path(ROOT) / \"models\" / \"qwen2.5\"\n",
    "QWEN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Qwen dir:\", QWEN_DIR)\n",
    "\n",
    "try:\n",
    "    ensure_models_downloaded(\n",
    "        qwen_dir=QWEN_DIR,\n",
    "        sdxl_dir=Path(ROOT) / \"models\" / \"sdxl\",  # unused by downloader (kept for compatibility)\n",
    "        hf_token=os.environ.get(\"MANGA_AI_HF_TOKEN\"),\n",
    "    )\n",
    "    print(\"Qwen model is present (downloaded if needed).\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"Qwen model download/setup failed. \"\n",
    "        \"If Qwen is gated, accept the license on HuggingFace and set MANGA_AI_HF_TOKEN. \"\n",
    "        f\"Original error: {e}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f505fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "req_path = Path(ROOT) / \"requirements.txt\"\n",
    "print(\"Installing from:\", req_path)\n",
    "\n",
    "if not req_path.exists():\n",
    "    raise FileNotFoundError(f\"requirements.txt not found at {req_path}\")\n",
    "\n",
    "# Install into the *current Jupyter kernel* environment\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(req_path)])\n",
    "print(\"Note: you may need to restart the kernel after installs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity checks (doesn't load the full ML pipelines)\n",
    "assert (QWEN_DIR / \"config.json\").exists(), \"Qwen config.json not found\"\n",
    "\n",
    "print(\"Sanity checks passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3742eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Deprecated) SDXL sanity checks removed because Animagine/SDXL was removed from the Qwen-only workflow.\n",
    "# Keep this cell as a no-op so running top-to-bottom doesn't fail.\n",
    "print(\"Skipping SDXL sanity checks (Animagine removed).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91ef0c",
   "metadata": {},
   "source": [
    "## Launch Web UI + Cloudflare Public URL\n",
    "\n",
    "Running the next cell will:\n",
    "- Start Gradio locally on port `7860`\n",
    "- Start a Cloudflare tunnel and print a public `https://...trycloudflare.com` URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from scripts.storyboard import generate_storyboard, save_storyboard\n",
    "\n",
    "print(\"Using Qwen model at:\", QWEN_DIR)\n",
    "\n",
    "basic_prompt = \"\"\"\n",
    "A shy high-school artist discovers a mysterious sketchbook that makes drawings come to life.\n",
    "First page: she finds the book after school in an empty art classroom during golden hour.\n",
    "Focus on emotions, small details, and a hint of supernatural mystery.\n",
    "\"\"\"\n",
    "\n",
    "sb = generate_storyboard(\n",
    "    story_prompt=basic_prompt,\n",
    "    model_dir=QWEN_DIR,\n",
    "    pages=1,\n",
    "    max_new_tokens=1600,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "out_path = Path(ROOT) / \"outputs\" / \"storyboard_qwen.json\"\n",
    "save_storyboard(sb, out_path)\n",
    "print(f\"Saved storyboard to: {out_path}\")\n",
    "\n",
    "print(\"\\n=== STORYBOARD SUMMARY ===\")\n",
    "print(f\"Title: {sb.title}\")\n",
    "print(f\"Logline: {sb.logline}\")\n",
    "print(f\"Style notes: {sb.style_notes}\")\n",
    "print(f\"\\nPages: {len(sb.pages)}\")\n",
    "\n",
    "for page in sb.pages:\n",
    "    print(f\"\\n--- Page {page.page_index} ---\")\n",
    "    for panel in page.panels:\n",
    "        x, y, w, h = panel.bbox_norm\n",
    "        print(f\"\\nPanel {panel.panel_id}\")\n",
    "        print(f\"  BBox (norm): x={x:.3f}, y={y:.3f}, w={w:.3f}, h={h:.3f}\")\n",
    "        print(f\"  Camera: {panel.camera_angle}, shot: {panel.shot}\")\n",
    "        print(f\"  Scene: {panel.scene}\")\n",
    "        print(f\"  Visual focus: {panel.visual_focus}\")\n",
    "        if panel.characters:\n",
    "            print(f\"  Characters: {', '.join(panel.characters)}\")\n",
    "        if panel.dialogue:\n",
    "            print(\"  Dialogue:\")\n",
    "            for line in panel.dialogue:\n",
    "                tone_str = f\" ({line.tone})\" if line.tone else \"\"\n",
    "                print(f\"    [{line.bubble_style}] {line.speaker}{tone_str}: {line.text}\")\n",
    "        print(f\"  Prompt: {panel.sdxl_prompt[:180]}...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
